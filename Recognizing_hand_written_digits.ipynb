{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Recognizing hand-written digits.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNqk+MX8nt8lnTLMennRf8C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DangMinh21/CS114.L22.KHCL/blob/main/Recognizing_hand_written_digits.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWbys5PuSHTc"
      },
      "source": [
        "# Recognizing hand-written digits\n",
        "\n",
        "This example shows how scikit-learn can be used to recognize images of\n",
        "hand-written digits, from 0-9."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilEYEZ4GiW_5"
      },
      "source": [
        "print(__doc__)\n",
        "\n",
        "# Author: Gael Varoquaux <gael dot varoquaux at normalesup dot org>\n",
        "# License: BSD 3 clause\n",
        "\n",
        "# Standard scientific Python imports\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Import datasets, classifiers and performance metrics\n",
        "from sklearn import datasets, svm, metrics\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xa0_8fZkSNcZ"
      },
      "source": [
        "## Digits dataset\n",
        "\n",
        "The digits dataset consists of 8x8\n",
        "pixel images of digits. The ``images`` attribute of the dataset stores\n",
        "8x8 arrays of grayscale values for each image. We will use these arrays to\n",
        "visualize the first 4 images. The ``target`` attribute of the dataset stores\n",
        "the digit each image represents and this is included in the title of the 4\n",
        "plots below.\n",
        "\n",
        "Note: if we were working from image files (e.g., 'png' files), we would load\n",
        "them using :func:`matplotlib.pyplot.imread`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5cyvg14ia-Y"
      },
      "source": [
        "digits = datasets.load_digits()\n",
        "\n",
        "_, axes = plt.subplots(nrows=1, ncols=4, figsize=(10, 3))\n",
        "for ax, image, label in zip(axes, digits.images, digits.target):\n",
        "    ax.set_axis_off()\n",
        "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "    ax.set_title('Training: %i' % label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJlP7McSSaxy"
      },
      "source": [
        "## Classification\n",
        "\n",
        "To apply a classifier on this data, we need to flatten the images, turning\n",
        "each 2-D array of grayscale values from shape ``(8, 8)`` into shape\n",
        "``(64,)``. Subsequently, the entire dataset will be of shape\n",
        "``(n_samples, n_features)``, where ``n_samples`` is the number of images and\n",
        "``n_features`` is the total number of pixels in each image.\n",
        "\n",
        "We can then split the data into train and test subsets and fit a support\n",
        "vector classifier on the train samples. The fitted classifier can\n",
        "subsequently be used to predict the value of the digit for the samples\n",
        "in the test subset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJAz3HBGic6k"
      },
      "source": [
        "# flatten the images\n",
        "n_samples = len(digits.images)\n",
        "data = digits.images.reshape((n_samples, -1))\n",
        "\n",
        "# Create a classifier: a support vector classifier\n",
        "clf = svm.SVC(gamma=0.001)\n",
        "\n",
        "# Split data into 50% train and 50% test subsets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    data, digits.target, test_size=0.5, shuffle=False)\n",
        "\n",
        "# Learn the digits on the train subset\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict the value of the digit on the test subset\n",
        "predicted = clf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVbW0gaVSzFQ"
      },
      "source": [
        "Below we visualize the first 4 test samples and show their predicted\n",
        "digit value in the title."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOWhovH7iglC"
      },
      "source": [
        "_, axes = plt.subplots(nrows=1, ncols=4, figsize=(10, 3))\n",
        "for ax, image, prediction in zip(axes, X_test, predicted):\n",
        "    ax.set_axis_off()\n",
        "    image = image.reshape(8, 8)\n",
        "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "    ax.set_title(f'Prediction: {prediction}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBcEx9xHijD1"
      },
      "source": [
        "print(f\"Classification report for classifier {clf}:\\n\"\n",
        "      f\"{metrics.classification_report(y_test, predicted)}\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIrzDp9hiliJ"
      },
      "source": [
        "disp = metrics.plot_confusion_matrix(clf, X_test, y_test)\n",
        "disp.figure_.suptitle(\"Confusion Matrix\")\n",
        "print(f\"Confusion matrix:\\n{disp.confusion_matrix}\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1S6qgfm7WhWf"
      },
      "source": [
        "# Phân tích trước khi thực hiện\n",
        "### Đặc điểm ảnh trong bộ dataset\n",
        "* kích thước: 8*8 grayscale\n",
        "* giá trị mỗi pixel nằm trong khoảng 0 - 15\n",
        "\n",
        "### Đặc điểm ảnh chụp được\n",
        "* Kích thước: 480*640 RBL\n",
        "* giá trị mỗi pixel nằm trong khoảng 0 - 255\n",
        "\n",
        "Sau khi chụp được hình từ webcam, thì chuyển đổi để ảnh chụp được có đặc điểm giống ảnh trong bộ dataset sau đó thực hiện predict."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fYgYm84TasJ"
      },
      "source": [
        "#WEBCAM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANUB9Mtyi0Tc"
      },
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z18Pv4MhTio2"
      },
      "source": [
        "#IMPORT THƯ VIỆN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ex61v7n5Own"
      },
      "source": [
        "import cv2 as cv\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRd3rB9vTprp"
      },
      "source": [
        "#CHỤP HÌNH SỐ ĐỂ NHẬN DẠNG\n",
        "* Chụp 6 hình lưu các số từ 1 đến 6 vào list images\n",
        "* tạo bộ target [1,2,3,4,5,6] tương ứng với nội dung ảnh"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fY6LdZwi0Th"
      },
      "source": [
        "images = []\n",
        "target = [1, 2, 3, 4, 5, 6]\n",
        "from IPython.display import Image\n",
        "temp = 0\n",
        "while(temp < 6):\n",
        "  try:\n",
        "    filename = take_photo()\n",
        "    print('Saved to {}'.format(filename))\n",
        "  \n",
        "  # Show the image which was just taken.\n",
        "    display(Image(filename))\n",
        "  except Exception as err:\n",
        "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "  # grant the page permission to access it.\n",
        "    print(str(err))\n",
        "  # chuyển ảnh về dạng grayscale rồi lưu vào images\n",
        "  image = cv.imread(filename, 0)\n",
        "  images.append(image)\n",
        "  temp +=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oH9hnJPmUlce"
      },
      "source": [
        "## 6 số chụp được từ webcam laptop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evHmccq57pxd"
      },
      "source": [
        "_, axes = plt.subplots(nrows=1, ncols=6, figsize=(200, 30))\n",
        "for ax, image, label in zip(axes, images, target):\n",
        "    ax.set_axis_off()\n",
        "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "    ax.set_title('target: %i' % label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVdIIctXLqqR"
      },
      "source": [
        "#chuyển images về ndarray để dễ sử lí\n",
        "images = np.array(images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyuEpr_RVRJN"
      },
      "source": [
        "print(images.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAzxOEhauKlv"
      },
      "source": [
        "# thực hiện chuyển ảnh từ kích thước (480, 640) về kích thước (8, 8)\n",
        "Images = []\n",
        "for i in range(6):\n",
        "  temp = cv.resize(images[i], (8, 8))\n",
        "  Images.append(temp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x73tDIyoQAUK"
      },
      "source": [
        "print(Images.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uswxn35AcVT"
      },
      "source": [
        "# xuất 6 ảnh sau khi thực hiện chuyển đổi\n",
        "Images = np.array(Images)\n",
        "_, axes = plt.subplots(nrows=1, ncols=6, figsize=(200, 30))\n",
        "for ax, image, label in zip(axes, Images, target):\n",
        "    ax.set_axis_off()\n",
        "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "    ax.set_title('target: %i' % label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLEP8BWCNPyh"
      },
      "source": [
        "# đưa ảnh về (64, 1) để thực hiện predict\n",
        "# đồng thời đưa giá trị mỗi pixel về trong khoảng (0, 15)\n",
        "images_flat = Images.reshape(6, 64)\n",
        "for i in range(len(images_flat)):\n",
        "  images_flat[i] = images_flat[i]/255*15\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1hlJp87RA_-"
      },
      "source": [
        "#thực hiện predict\n",
        "y_pred = clf.predict(images_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-m5NXXARhvM"
      },
      "source": [
        "print(y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAaNm10DRDNg"
      },
      "source": [
        "# 6 ảnh sau khi thực hiện predict cùng label được predict\n",
        "_, axes = plt.subplots(nrows=1, ncols=6, figsize=(10, 3))\n",
        "for ax, image, prediction in zip(axes, images_flat, y_pred):\n",
        "    ax.set_axis_off()\n",
        "    image = image.reshape(8, 8)\n",
        "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "    ax.set_title(f'Prediction: {prediction}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCDoy5UzWXX-"
      },
      "source": [
        "## kết quả so sánh sau khi predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4Pa0TkoS-vY"
      },
      "source": [
        "print(f\"Classification report for classifier {clf}:\\n\"\n",
        "      f\"{metrics.classification_report(target, y_pred)}\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oL9zAOy0THW9"
      },
      "source": [
        "disp = metrics.plot_confusion_matrix(clf, images_flat, target)\n",
        "disp.figure_.suptitle(\"Confusion Matrix\")\n",
        "print(f\"Confusion matrix:\\n{disp.confusion_matrix}\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFLU9tXqX1Fn"
      },
      "source": [
        "# TRẢ LỜI CÂU HỎI\n",
        "### Kết quả chạy thực tế với webcam của laptop và giấy viết tay của các bạn có tốt không?\n",
        ">kết quả không được tốt, cụ thể 6 ảnh chụp được ở trên không predict đúng ảnh nào.\n",
        "### Ủa mà nhìn vào đâu để kết luận là tốt hay không?\n",
        ">nhìn vào kết quả so sánh thấy được độ chính xác không tốt.\n",
        "### Nếu không tốt thì lý do tại sao?\n",
        "* webcam laptop chụp hình có chất lượng không tốt, điều kiện ánh sáng, môi trường không phù hợp.\n",
        "* sau khi chuyển ảnh chụp được từ webcam sang ảnh có đặc điểm giống ảnh trong dataset thì đã mất đi nhiều thông tin, xử kí ảnh không tốt.\n",
        "* Model bị overfit với bộ dataset.\n",
        "\n",
        "### Nếu tốt thì tiếp theo có thể dùng model digits recognition này vào các bài toán phức tạp hơn như nhận dạng biển số nhà không?\n",
        "> Không sử dụng model này vào thực tế nhận dạng biển số được. Để sử dụng model trong thực tế cần cập nhập lại bộ dataset cho phù hợp cộng với sử đụng các kĩ thuật để chuyển đổi ảnh cho phù hợp"
      ]
    }
  ]
}